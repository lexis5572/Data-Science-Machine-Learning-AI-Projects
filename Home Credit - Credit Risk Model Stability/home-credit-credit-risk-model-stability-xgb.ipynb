{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":50160,"databundleVersionId":7921029,"sourceType":"competition"}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\ntrain = pd.read_csv('/kaggle/input/home-credit-credit-risk-model-stability/csv_files/train/train_base.csv')\ntest = pd.read_csv('/kaggle/input/home-credit-credit-risk-model-stability/csv_files/test/test_base.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T07:43:01.490921Z","iopub.execute_input":"2025-01-02T07:43:01.491338Z","iopub.status.idle":"2025-01-02T07:43:02.700266Z","shell.execute_reply.started":"2025-01-02T07:43:01.491302Z","shell.execute_reply":"2025-01-02T07:43:02.699266Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T07:43:02.701628Z","iopub.execute_input":"2025-01-02T07:43:02.701882Z","iopub.status.idle":"2025-01-02T07:43:02.790097Z","shell.execute_reply.started":"2025-01-02T07:43:02.701862Z","shell.execute_reply":"2025-01-02T07:43:02.789425Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1526659 entries, 0 to 1526658\nData columns (total 5 columns):\n #   Column         Non-Null Count    Dtype \n---  ------         --------------    ----- \n 0   case_id        1526659 non-null  int64 \n 1   date_decision  1526659 non-null  object\n 2   MONTH          1526659 non-null  int64 \n 3   WEEK_NUM       1526659 non-null  int64 \n 4   target         1526659 non-null  int64 \ndtypes: int64(4), object(1)\nmemory usage: 58.2+ MB\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T07:43:02.791570Z","iopub.execute_input":"2025-01-02T07:43:02.791778Z","iopub.status.idle":"2025-01-02T07:43:02.799727Z","shell.execute_reply.started":"2025-01-02T07:43:02.791761Z","shell.execute_reply":"2025-01-02T07:43:02.798868Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10 entries, 0 to 9\nData columns (total 4 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   case_id        10 non-null     int64 \n 1   date_decision  10 non-null     object\n 2   MONTH          10 non-null     int64 \n 3   WEEK_NUM       10 non-null     int64 \ndtypes: int64(3), object(1)\nmemory usage: 448.0+ bytes\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"numerical_columns_train = train.select_dtypes(include=['int64', 'float64'])\nnumerical_columns_test = test.select_dtypes(include=['int64', 'float64'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T07:43:02.801020Z","iopub.execute_input":"2025-01-02T07:43:02.801363Z","iopub.status.idle":"2025-01-02T07:43:02.830250Z","shell.execute_reply.started":"2025-01-02T07:43:02.801341Z","shell.execute_reply":"2025-01-02T07:43:02.829358Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Define a function to cap outliers based on the 1st and 99th percentiles\ndef cap_outliers(df, columns):\n    for column in columns:\n        lower_bound = df[column].quantile(0.01)\n        upper_bound = df[column].quantile(0.99)\n        df[column] = df[column].clip(lower=lower_bound, upper=upper_bound)\n    return df\n\n# Cap outliers in numerical columns for train and test datasets\nnumerical_columns_train = numerical_columns_train.columns\nnumerical_columns_test = numerical_columns_test.columns\n\ntrain_capped = cap_outliers(train.copy(), numerical_columns_train)\ntest_capped = cap_outliers(test.copy(), numerical_columns_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T07:43:02.831127Z","iopub.execute_input":"2025-01-02T07:43:02.831440Z","iopub.status.idle":"2025-01-02T07:43:03.034684Z","shell.execute_reply.started":"2025-01-02T07:43:02.831417Z","shell.execute_reply":"2025-01-02T07:43:03.033643Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Perform one-hot encoding for categorical columns in train and test datasets\ntrain_encoded = pd.get_dummies(train_capped, columns=['date_decision'], drop_first=True)\ntest_encoded = pd.get_dummies(test_capped, columns=['date_decision'], drop_first=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T07:43:03.035774Z","iopub.execute_input":"2025-01-02T07:43:03.036086Z","iopub.status.idle":"2025-01-02T07:43:05.394532Z","shell.execute_reply.started":"2025-01-02T07:43:03.036055Z","shell.execute_reply":"2025-01-02T07:43:05.393757Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Set up features and target for the train dataset\nX_train = train_encoded[['MONTH', 'WEEK_NUM']]\nX_test = test_encoded[['MONTH', 'WEEK_NUM']]\ny_train = train_encoded['target']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T07:43:05.395367Z","iopub.execute_input":"2025-01-02T07:43:05.395688Z","iopub.status.idle":"2025-01-02T07:43:05.405272Z","shell.execute_reply.started":"2025-01-02T07:43:05.395659Z","shell.execute_reply":"2025-01-02T07:43:05.404406Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Perform train-test split with stratification\nX_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n    X_train, y_train, test_size=0.25, stratify=y_train, random_state=42\n)\n\nX_train_split.shape, X_val_split.shape, y_train_split.shape, y_val_split.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T07:43:05.407518Z","iopub.execute_input":"2025-01-02T07:43:05.407748Z","iopub.status.idle":"2025-01-02T07:43:06.447675Z","shell.execute_reply.started":"2025-01-02T07:43:05.407729Z","shell.execute_reply":"2025-01-02T07:43:06.446718Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"((1144994, 2), (381665, 2), (1144994,), (381665,))"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"%%time\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score\nimport xgboost as xgb\nimport numpy as np\n\n# Initialize KFold\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\n# Initialize the scaler\nscaler = StandardScaler()\n\n# Initialize the model\nmodel = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)))\n\ngini_scores = []\n\nfor train_index, val_index in kf.split(X_train):\n    # Split the data into training and validation sets\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n\n    # Scale the features\n    X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n    X_val_fold_scaled = scaler.transform(X_val_fold)\n\n    # Train the model\n    model.fit(X_train_fold_scaled, y_train_fold)\n\n    # Make predictions on the validation set\n    y_val_pred_proba = model.predict_proba(X_val_fold_scaled)\n\n    # Evaluate Gini coefficient (2 * AUC - 1)\n    auc = roc_auc_score(y_val_fold, y_val_pred_proba[:, 1])  # Use probabilities for the positive class\n    gini = 2 * auc - 1\n    gini_scores.append(gini)\n\n# Calculate the average Gini coefficient\naverage_gini = np.mean(gini_scores)\naverage_gini","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T07:43:06.448903Z","iopub.execute_input":"2025-01-02T07:43:06.449383Z","iopub.status.idle":"2025-01-02T07:43:47.901521Z","shell.execute_reply.started":"2025-01-02T07:43:06.449359Z","shell.execute_reply":"2025-01-02T07:43:47.900606Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 2min 37s, sys: 433 ms, total: 2min 38s\nWall time: 41.4 s\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"0.14290845304092686"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import pickle\n\n# Save the trained model into a pickle file\nwith open('home_credit_risk_xgb_model.pkl', 'wb') as file:\n    pickle.dump(model, file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T07:43:47.902520Z","iopub.execute_input":"2025-01-02T07:43:47.902847Z","iopub.status.idle":"2025-01-02T07:43:47.911828Z","shell.execute_reply.started":"2025-01-02T07:43:47.902813Z","shell.execute_reply":"2025-01-02T07:43:47.911162Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\n# Scale the test data\nX_test_scaled = scaler.transform(X_test)\n\n# Train the model on the entire training data\nmodel.fit(scaler.fit_transform(X_train), y_train)\n\n# Predict on the test data\ny_test_pred = model.predict(X_test_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T07:43:47.912658Z","iopub.execute_input":"2025-01-02T07:43:47.913130Z","iopub.status.idle":"2025-01-02T07:43:58.339786Z","shell.execute_reply.started":"2025-01-02T07:43:47.913108Z","shell.execute_reply":"2025-01-02T07:43:58.339098Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Calculate the percentage of clients predicted to default on their loans\ndefault_probability = (y_val_pred_proba == 1).sum() / len(y_val_pred_proba) * 100\ndefault_probability","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T07:46:50.422375Z","iopub.execute_input":"2025-01-02T07:46:50.422711Z","iopub.status.idle":"2025-01-02T07:46:50.428491Z","shell.execute_reply.started":"2025-01-02T07:46:50.422673Z","shell.execute_reply":"2025-01-02T07:46:50.427758Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0.0"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"- The percentage of clients predicted to default on their loans 0%","metadata":{}}]}